% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2024-----%

@UNPUBLISHED{orozco2024IPaspire,
  author = {Rafael Orozco and Ali Siahkoohi and Mathias Louboutin and Felix J. Herrmann},
  title = {ASPIRE: Iterative Amortized Posterior Inference for Bayesian Inverse Problems},
  year = {2024},
  month = {5},
  abstract = {Due to their uncertainty quantification, Bayesian solutions to
inverse problems are the framework of choice in applications that are risk
averse. These benefits come at the cost of computations that are in general,
intractable. New advances in machine learning and variational inference (VI)
have lowered the computational barrier by learning from examples. Two VI
paradigms have emerged that represent different tradeoffs: amortized and
non-amortized. Amortized VI can produce fast results but due to generalizing
to many observed datasets it produces suboptimal inference results.
Non-amortized VI is slower at inference but finds better posterior
approximations since it is specialized towards a single observed dataset.
Current amortized VI techniques run into a sub-optimality wall that can not
be improved without more expressive neural networks or extra training data.
We present a solution that enables iterative improvement of amortized
posteriors that uses the same networks architectures and training data. The
benefits of our method requires extra computations but these remain frugal
since they are based on physics-hybrid methods and summary statistics.
Importantly, these computations remain mostly offline thus our method
maintains cheap and reusable online evaluation while bridging the
approximation gap these two paradigms. We denote our proposed method
ASPIRE - Amortized posteriors with Summaries that are
Physics-based and Iteratively REfined. We first validate our
method on a stylized problem with a known posterior then demonstrate its
practical use on a high-dimensional and nonlinear transcranial medical
imaging problem with ultrasound. Compared with the baseline and previous
methods from the literature our method stands out as an computationally
efficient and high-fidelity method for posterior inference.},
  keywords = {Normalizing flows, amortization gap, Bayesian inference, simulation-based inference, amortized variational inference, medical imaging},
  doi = {10.48550/arXiv.2405.05398}
}

@UNPUBLISHED{yin2024wiser,
  author = {Ziyi Yin and Rafael Orozco and Felix J. Herrmann},
  title = {WISER: multimodal variational inference for full-waveform inversion without dimensionality reduction},
  year = {2024},
  month = {5},
  abstract = {We present a semi-amortized variational inference framework designed for computationally feasible uncertainty quantification in 2D full-waveform inversion to explore the multimodal posterior distribution without dimensionality reduction. The framework is called WISER, short for full-Waveform variational Inference via Subsurface Extensions with Refinements. WISER leverages the power of generative artificial intelligence to perform approximate amortized inference that is low-cost albeit showing an amortization gap. This gap is closed through non-amortized refinements that make frugal use of acoustic wave physics. Case studies illustrate that WISER is capable of full-resolution, computationally feasible, and reliable uncertainty estimates of velocity models and imaged reflectivities.},
  keywords = {WISER, WISE, FWI, imaging, CIG, conditional normalizing flows, Bayesian inference, amortized variational inference, uncertainty quantification, deep learning, inverse problems, summary statistics, MVA},
  url = {https://slim.gatech.edu/Publications/Public/Submitted/2024/yin2024wiser/WISER.html},
  doi = {10.13140/RG.2.2.34906.15044}
}

@UNPUBLISHED{zeng2024IMAGEefw,
  author = {Yunlin Zeng and Rafael Orozco and Ziyi Yin and Felix J. Herrmann},
  title = {Enhancing Full-Waveform Variational Inference through Stochastic Resampling and Data Augmentation},
  year = {2024},
  month = {3},
  keywords = {WISE, FWI, RTM, imaging, CIG, conditional normalizing flows, Bayesian inference, amortized variational inference, uncertainty quantification, deep learning, inverse problems, summary statistics, MVA},
  url = {https://slimgroup.github.io/IMAGE2024/Yunlin_Zeng2024SEG/paper.html}
}

@UNPUBLISHED{erdinc2024IMAGEggm,
  author = {Huseyin Tuna Erdinc and Rafael Orozco and Felix J. Herrmann},
  title = {Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations},
  year = {2024},
  month = {3},
  abstract = {Diffusion generative models are powerful frameworks for learning high-dimensional distributions and synthesizing high-fidelity images. However, their efficacy in training predominantly hinges on the availability of complete, high-quality training datasets, a condition that often proves unattainable, particularly in the domain of subsurface velocity-model generation. In this work, we propose to synthesize proxy subsurface velocities from incomplete well and imaged seismic observations by introducing additional corruptions to the observations during the training phase. In this context, proxy velocity models refer to random realizations of subsurface velocities that are close in distribution to the actual subsurface velocities. These proxy models can be used as priors to train neural networks with simulation-based inference. Our approach facilitates the generation of these proxy velocity samples by utilizing available datasets composed merely of seismic images and 5 (for now) wells per seismic image.After training, our foundation generative model permits the generation of velocity samples derived from unseen RTMs without the need of having access to wells.},
  keywords = {kriging, diffusion, geostatistics, generative modeling, deep learning, velocity model building},
  url = {https://slimgroup.github.io/IMAGE2024/erdinc2024SEG/abstract.html}
}

@UNPUBLISHED{rex2024IMAGEvc,
  author = {Richard Rex and Ziyi Yin and Felix J. Herrmann},
  title = {Velocity Continuation for Common Image Gathers with Fourier Neural Operators},
  year = {2024},
  month = {3},
  abstract = {Common-image gathers (CIGs) are pivotal in migration-velocity analysis (MVA). However, MVA is often hindered by the computational burden of traditional migration methods. To bypass these limitations, we introduce a neural-surrogate learning approach that utilizes Fourier Neural Operators (FNOs, Li et al. 2020) to accelerate MVA. Following the velocity-continuation scheme of Siahkoohi, Louboutin, and Herrmann (2022), we train a survey-specific FNO to map the CIGs associated with one migration-velocity model to another without remigration. This methodology leverages the capacity of FNOs to approximate complex PDE-based mappings, rendering computational cost at inference negligible, thereby expediting MVA. By enabling rapid generation and evaluation of CIGs across various velocity models, it offers a pathway to quickly examine velocity models according to preferred properties and to quantify uncertainties in imaged reflectivities at the same time. Additionally, this methodology paves the way for inverse design optimization, updating velocity models to produce CIGs with desirable characteristics.},
  keywords = {FNO, CIG, velocity continuation, uncertainty quantification, deep learning, imaging},
  url = {https://slimgroup.github.io/IMAGE2024/Rex2024SEG/paper.html}
}

@UNPUBLISHED{gahlot2024IMAGEdt,
  author = {Abhinav Prakash Gahlot and Haoyun Li and Ziyi Yin and Rafael Orozco and Felix J. Herrmann},
  title = {A Digital Twin for Geological Carbon Storage with Controlled Injectivity},
  year = {2024},
  month = {3},
  abstract = {We present an uncertainty-aware Digital Twin (DT) for geologic carbon storage (GCS), capable of handling multimodal time-lapse data and controlling CO2 injectivity to mitigate reservoir fracturing risks. In GCS, DT represents virtual replicas of subsurface systems that incorporate real-time data and advanced generative Artificial Intelligence (genAI) techniques, including neural posterior density estimation via simulation-based inference and sequential Bayesian inference. These methods enable the effective monitoring and control of CO2 storage projects, addressing challenges such as subsurface complexity, operational optimization, and risk mitigation. By integrating diverse monitoring data, e.g., geophysical well observations and imaged seismic, DT can bridge the gaps between seemingly distinct fields like geophysics and reservoir engineering. In addition, the recent advancements in genAI also facilitate DT with principled uncertainty quantification. Through recursive training and inference, DT utilizes simulated current state samples, e.g., CO2 saturation, paired with corresponding geophysical field observations to train its neural networks and enable posterior sampling upon receiving new field data. However, it lacks decision-making and control capabilities, which is necessary for full DT functionality. This study aims to demonstrate how DT can inform decision-making processes to prevent risks such as cap rock fracturing during CO2 storage operations.},
  keywords = {GCS, digital twin, sequential Bayes, conditional normalizing flows, Bayesian inference, uncertainty quantification, deep learning, control},
  url = {https://slimgroup.github.io/IMAGE2024/GahlotLi2024SEG/paper.html},
  doi = {10.48550/arXiv.2403.19819}
}

@UNPUBLISHED{orozco2024IMAGEbeacon,
  author = {Rafael Orozco and Abhinav Prakash Gahlot and Felix J. Herrmann},
  title = {BEACON: Bayesian Experimental design Acceleration with Conditional Normalizing flows - a case study in optimal monitor well placement for CO2 sequestration},
  year = {2024},
  month = {3},
  abstract = {CO2 sequestration is a crucial engineering solution for mitigating climate change.
However, the uncertain nature of reservoir properties, necessitates rigorous monitoring of CO2 plumes to prevent risks such as leakage, induced seismicity, or
breaching licensed boundaries. To address this, project managers use borehole
wells for direct CO2 and pressure monitoring at specific locations. Given the high
costs associated with drilling, it is crucial to strategically place a limited number of
wells to ensure maximally effective monitoring within budgetary constraints. Our
approach for selecting well locations integrates fluid-flow solvers for forecasting
plume trajectories with generative neural networks for plume inference uncertainty.
Our methodology is extensible to three-dimensional domains and is developed
within a Bayesian framework for optimal experimental design, ensuring scalability
and mathematical optimality. We use a realistic case study to verify these claims
by demonstrating our method's application in a large scale domains and optimal
performance as compared to baseline well placement.},
  keywords = {GCS, conditional normalizing flows, Bayesian inference, amortized variational inference, uncertainty quantification, deep learning, inverse problems, OED},
  doi = {10.48550/arXiv.2404.00075}
}

@UNPUBLISHED{yin2024IMAGEwiser,
  author = {Ziyi Yin and Rafael Orozco and Mathias Louboutin and Felix J. Herrmann},
  title = {WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements},
  year = {2024},
  month = {3},
  abstract = {We introduce a cost-effective Bayesian inference method for full-waveform inversion (FWI) to quantify uncertainty in migration-velocity models and its impact on imaging. Our method targets inverse uncertainty due to null-space of the wave modeling operators and observational noise, and forward uncertainty where the uncertainty in velocity models is propagated to uncertainty in amplitude and positioning of imaged reflectivities. This is achieved by integrating generative artificial intelligence (genAI) with physics-informed common-image gathers (CIGs), which greatly reduces reliance on accurate initial FWI-velocity models. In addition, we illustrate the capability of fine-tuning the generative AI networks with frugal physics-based refinements to improve the inference accuracy.},
  keywords = {WISE, WISER, FWI, RTM, imaging, CIG, conditional normalizing flows, Bayesian inference, amortized variational inference, uncertainty quantification, deep learning, inverse problems, summary statistics, MVA},
  url = {https://slimgroup.github.io/IMAGE2024/yin2024SEG/paper.html}
}

@UNPUBLISHED{yin2024tfp,
  author = {Ziyi Yin and Mathias Louboutin and Olav Møyner and Felix J. Herrmann},
  title = {Time-lapse full-waveform permeability inversion: a feasibility study},
  year = {2024},
  month = {3},
  abstract = {Time-lapse seismic monitoring necessitates integrated workflows that combine seismic and reservoir modeling to enhance reservoir property estimation. We present a feasibility study of an end-to-end inversion framework that directly inverts for permeability from prestack time-lapse seismic data. To assess the method’s robustness, we design experiments focusing on its sensitivity to initial models and potential errors in modeling. Our study leverages the Compass model to simulate CO2 storage in saline aquifers, which is derived from well and seismic data from the North Sea, a candidate site for geological carbon storage.},
  keywords = {gcs, 4D, time-lapse, ccs, coupled inversion, end-to-end, fluid-flow, inversion, monitoring},
  url = {https://slim.gatech.edu/Publications/Public/Submitted/2024/yin2024tfp/paper.html},
  doi = {10.48550/arXiv.2403.04083}
}

%-----2023-----%

@UNPUBLISHED{orozco2023invnet,
  author = {Rafael Orozco and Philipp A. Witte and Mathias Louboutin and Ali Siahkoohi and Gabrio Rizzuti and Bas Peters and Felix J. Herrmann},
  title = {InvertibleNetworks.jl: A Julia package for scalable normalizing flows},
  year = {2023},
  month = {12},
  abstract = {InvertibleNetworks.jl is a Julia package designed for the scalable implementation of normalizing flows, a method for density estimation and sampling in high-dimensional distributions. This package excels in memory efficiency by leveraging the inherent invertibility of normalizing flows, which significantly reduces memory requirements during backpropagation compared to existing normalizing flow packages that rely on automatic differentiation frameworks. InvertibleNetworks.jl has been adapted for diverse applications, including seismic imaging, medical imaging, and CO2 monitoring, demonstrating its effectiveness in learning high-dimensional distributions.},
  keywords = {normalizing flows, software, conditional normalizing flows, Bayesian inference, uncertainty quantification, deep learning, inverse problems, memory, HPC, computing},
  doi = {10.48550/arXiv.2312.13480}
}