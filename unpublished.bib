% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2023-----%

@UNPUBLISHED{louboutin2023rte,
  author = {Mathias Louboutin and Felix J. Herrmann},
  title = {Wave-based inversion at scale on GPUs with randomized trace estimation},
  year = {2023},
  month = {03},
  abstract = {Thanks to continued performance improvements in software and
hardware, wave-equation based imaging technologies, such full-waveform
inversion and reverse-time migration, are becoming more common place.
However, wide-spread adaptation of these advanced imaging modalities has not
yet materialized because current implementations are not able to reap the
full benefits from accelerators, in particular those offered by memory-scarce
graphics processing units. Through the use of randomized trace estimation, we
overcome the memory bottleneck of this type of hardware. At the cost of
limited computational overhead and controllable incoherent errors in the
gradient, the memory footprint of adjoint-state methods is reduced
drastically. Thanks to this relatively simple to implement memory reduction
via an approximate imaging condition, we are able to benefit from graphics
processing units without memory offloading. We demonstrate the performance of
the proposed algorithm on acoustic 2- and 3-D full-waveform inversion
examples and on the formation of image gathers in transverse tilted isotropic
media.},
  keywords = {FWI, Stochastic, Random trace, CIG, GPUs},
  url = {https://slim.gatech.edu/Publications/Public/Submitted/2023/louboutin2023rte/paper.html},
}

%-----2022-----%

@UNPUBLISHED{grady2022SCtll,
  author = {Thomas J. Grady II and Rishi Khan and Mathias Louboutin and Ziyi Yin and Philipp A. Witte and Ranveer Chandra and Russell J. Hewett and Felix J. Herrmann},
  title = {Model-Parallel Fourier Neural Operators as Learned Surrogates for Large-Scale Parametric PDEs},
  year = {2022},
  month = {04},
  abstract = {Fourier neural operators (FNOs) are a recently introduced neural network architecture for learning solution operators of partial differential equations (PDEs), which have been shown to perform significantly better than comparable deep learning approaches. Once trained, FNOs can achieve speed-ups of multiple orders of magnitude over conventional numerical PDE solvers. However, due to the high dimensionality of their input data and network weights, FNOs have so far only been applied to two-dimensional or small three-dimensional problems. To remove this limited problem-size barrier, we propose a model-parallel version of FNOs based on domain-decomposition of both the input data and network weights. We demonstrate that our model-parallel FNO is able to predict time-varying PDE solutions of over 2.6 billion variables on Perlmutter using up to 512 A100 GPUs and show an example of training a distributed FNO on the Azure cloud for simulating multiphase CO2 dynamics in the Earth's subsurface.},
  keywords = {Fourier neural operators, HPC, large-scale, CCS, deep learning, Operator Learning, Model Parallelism, Multiphase Flow},
  software = {https://github.com/slimgroup/dfno},
  url = {https://slim.gatech.edu/Publications/Public/Submitted/2022/grady2022SCtll/grady2022SCtll.pdf},
}
