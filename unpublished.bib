% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2015-----%

@UNPUBLISHED{dasilva2015EAGEogt,
  author = {Curt Da Silva and Felix J. Herrmann},
  title = {Off the grid tensor completion for seismic data interpolation},
  year = {2015},
  abstract = {The practical realities of acquiring seismic data in a
                  realistic survey are often at odds with the
                  stringent requirements of Shannon-Nyquist-based
                  sampling theory. The unpredictable movement of the
                  ocean`s currents can be detrimental in acquiring
                  exactly equally-spaced samples while sampling at
                  Nyquist-rates are expensive, given the huge
                  dimensionality and size of the data volume. Recent
                  work in matrix and tensor completion for seismic
                  data interpolation aim to alleviate such stringent
                  Nyquist-based sampling requirements but are
                  fundamentally posed on a regularly-spaced grid. In
                  this work, we extend our previous results in using
                  the so-called Hierarchical Tucker (HT) tensor format
                  for recovering seismic data to the irregularly
                  sampled case. We introduce an interpolation operator
                  that resamples our tensor from a regular grid (in
                  which we impose our low-rank constraints) to our
                  irregular sampling grid. Our framework is very
                  flexible and efficient, depending primarily on the
                  computational costs of this operator. We demonstrate
                  the superiority of this approach on a realistic BG
                  data set compared to using low-rank tensor methods
                  that merely use binning.},
  keywords = {EAGE, hierarchical tucker, structured tensor, tensor interpolation, off the grid, irregular sampling},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/dasilva2015EAGEogt/dasilva2015EAGEogt.html}
}


@UNPUBLISHED{esser2015EAGElcs,
  author = {Ernie Esser and Tim T.Y. Lin and Rongrong Wang and Felix J. Herrmann},
  title = {A lifted $\ell_1/\ell_2$ constraint for sparse blind deconvolution},
  year = {2015},
  abstract = {We propose a modification to a sparsity constraint based
                  on the ratio of $\ell_1$ and $\ell_2$ norms for
                  solving blind seismic deconvolution problems in
                  which the data consist of linear convolutions of
                  different sparse reflectivities with the same source
                  wavelet. We also extend the approach to the
                  Estimation of Primaries by Sparse Inversion (EPSI)
                  model, which includes surface related multiples.
                  Minimizing the ratio of $\ell_1$ and $\ell_2$ norms
                  has been previously shown to promote sparsity in a
                  variety of applications including blind
                  deconvolution. Most existing implementations are
                  heuristic or require smoothing the $\ell_1/\ell_2$
                  penalty. Lifted versions of $\ell_1/\ell_2$
                  constraints have also been proposed but are
                  challenging to implement. Inspired by the lifting
                  approach, we propose to split the sparse signals
                  into positive and negative components and apply an
                  $\ell_1/\ell_2$ constraint to the difference,
                  thereby obtaining a constraint that is easy to
                  implement without smoothing the $\ell_1$ or $\ell_2$
                  norms. We show that a method of multipliers
                  implementation of the resulting model can recover
                  source wavelets that are not necessarily minimum
                  phase and approximately reconstruct the sparse
                  reflectivities. Numerical experiments demonstrate
                  robustness to the initialization as well as to noise
                  in the data.},
  keywords = {EAGE, blind deconvolution, EPSI},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/esser2015EAGElcs/esser2015EAGElcs.html}
}


@UNPUBLISHED{esser2015SEGasd,
  author = {Ernie Esser and Lluís Guasch and Tristan van Leeuwen and Aleksandr Y. Aravkin and Felix J. Herrmann},
  title = {Automatic salt delineation --- {Wavefield} {Reconstruction} {Inversion} with convex constraints},
  year = {2015},
  abstract = {We extend full-waveform inversion by Wavefield
                  Reconstruction Inversion by including convex
                  constraints on the model. Contrary to the
                  conventional adjoint-state formulations, Wavefield
                  Reconstruction Inversion has the advantage that the
                  Gauss-Newton Hessian is well approximated by a
                  diagonal scaling, which allows us to add convex
                  constraints, such as the box- and the
                  edge-preserving total-variation constraint, on the
                  square slowness without incurring significant
                  increases in computational costs. As the examples
                  demonstrate, including these constraints yields far
                  superior results in complex geological areas that
                  contain high-velocity high-contrast bodies
                  (e.g. salt or basalt). Without these convex
                  constraints, adjoint-state and Wavefield
                  Reconstruction Inversion get trapped in local minima
                  for poor starting models.},
  keywords = {SEG, full-waveform inversion, convex constraints, total-variation norm, salt, private},
  note = {(submitted to the SEG conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Conferences/SEG/2015/esser2015SEGasd/esser2015SEGasd.html}
}


@UNPUBLISHED{fang2015EAGEsew,
  author = {Zhilong Fang and Felix J. Herrmann},
  title = {Source estimation for {Wavefield} {Reconstruction} {Inversion}},
  year = {2015},
  abstract = {Wavefield reconstruction inversion is a new approach to
                  waveform based inversion that helps overcome the
                  `cycle skipping' problem. However, like most
                  waveform based inversion methods, wavefield
                  reconstruction inversion also requires good source
                  wavelets. Without correct source wavelets,
                  wavefields cannot be reconstructed correctly and the
                  velocity model cannot be updated correctly
                  neither. In this work, we propose a source
                  estimation method for wavefield reconstruction
                  inversion based on the variable projection method.
                  In this method, we reconstruct wavefields and
                  estimate source wavelets simultaneously by solving
                  an extended least-squares problem, which contains
                  source wavelets. This approach does not increase the
                  computational cost compared to conventional
                  wavefield reconstruction inversion. Numerical
                  results illustrates with our source estimation
                  method we are able to recover source wavelets and
                  obtain inversion results that are comparable to
                  results obtained with true source wavelets.},
  keywords = {EAGE, source estimation, WRI},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/fang2015EAGEsew/fang2015EAGEsew.html}
}


@UNPUBLISHED{fang2015EAGEuqw,
  author = {Zhilong Fang and Chia Ying Lee and Curt Da Silva and Felix J. Herrmann and Rachel Kuske},
  title = {Uncertainty quantification for {Wavefield} {Reconstruction} {Inversion}},
  year = {2015},
  abstract = {In this work, we propose a method to quantify the
                  uncertainty of wavefield reconstruction inversion
                  under the framework of Bayesian inference. Unlike
                  the conventional method using the wave equation as
                  the forward mapping, we involve the wave equation
                  misfit in the posterior distribution and propose a
                  new posterior distribution. The negative
                  log-likelihood of the new distribution is less
                  oscillatory than that of the conventional posterior
                  distribution, and its Gauss-Newton Hessian is a
                  diagonal matrix that can be generated without any
                  additional computational cost. We use the diagonal
                  Gauss-Newton Hessian to derive an approximate
                  Gaussian distribution at the maximum likelihood
                  point to quantify the uncertainty. This method makes
                  the uncertainty quantification for WRI
                  computationally tractable and is able to provide
                  reasonable uncertainty analysis based on our
                  numerical results.},
  keywords = {EAGE, UQ, WRI, FWI},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/fang2015EAGEuqw/fang2015EAGEuqw.html}
}


@UNPUBLISHED{herrmann2015SIAMpcf,
  author = {Felix J. Herrmann and Bas Peters},
  title = {Pros and cons of full- and reduced-space methods for {Wavefield} {Reconstruction} {Inversion}},
  year = {2015},
  abstract = {By insisting on fitting observed data, Wavefield
                  Reconstruction Inversion (WRI) is no longer cycle
                  skipped and therefore less reliant on the accuracy
                  of starting models. While extending the search space
                  mitigates local minima, there are challenges scaling
                  to 3D seismic when using reduced-space methods that
                  require accurate solves. Conversely, full-space
                  methods allow for inaccurate solves but require
                  storage of all wavefields. We weigh pros and cons of
                  these two approaches in the seismic context.},
  keywords = {SIAM, WRI, FWI, private},
  note = {(to be presented at the SIAM Conference on Mathematical and Computational Issues in the Geosciences, June 29 - July 2, Stanford University, California)}
}


@UNPUBLISHED{herrmann2015SIAMwri,
  author = {Felix J. Herrmann},
  title = {Wavefield {Reconstruction} {Inversion} – reaping the benefits from extending the search space},
  year = {2015},
  keywords = {SIAM, WRI, private},
  note = {(to be presented at the SIAM Conference on Mathematical and Computational Issues in the Geosciences, June 29 - July 2, Stanford University, California)}
}


@UNPUBLISHED{herrmann2015EAGEfom,
  author = {Felix J. Herrmann and Ning Tu and Ernie Esser},
  title = {Fast "online" migration with {Compressive} {Sensing}},
  year = {2015},
  abstract = {We present a novel adaptation of a recently developed
                  relatively simple iterative algorithm to solve
                  large-scale sparsity-promoting optimization
                  problems. Our algorithm is particularly suitable to
                  large-scale geophysical inversion problems, such as
                  sparse least-squares reverse-time migration or
                  Kirchoff migration since it allows for a tradeoff
                  between parallel computations, memory allocation,
                  and turnaround times, by working on subsets of the
                  data with different sizes. Comparison of the
                  proposed method for sparse least-squares imaging
                  shows a performance that rivals and even exceeds the
                  performance of state-of-the art one-norm solvers
                  that are able to carry out least-squares migration
                  at the cost of a single migration with all data.},
  keywords = {EAGE, LSRTM},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/herrmann2015EAGEfom/herrmann2015EAGEfom.html}
}


@UNPUBLISHED{kumar2015EAGEmcu,
  author = {Rajiv Kumar and Oscar Lopez and Ernie Esser and Felix J. Herrmann},
  title = {Matrix completion on unstructured grids : {2-D} seismic data regularization and interpolation},
  year = {2015},
  abstract = {Seismic data interpolation via rank-minimization
                  techniques has been recently introduced in the
                  seismic community. All the existing
                  rank-minimization techniques assume the recording
                  locations to be on a regular grid, e.g., sampled
                  periodically, but seismic data are typically
                  irregularly sampled along spatial axes. Other than
                  the irregularity of the sampled grid, we often have
                  missing data. In this paper, we study the effect of
                  grid irregularity to conduct matrix completion on a
                  regular grid for unstructured data. We propose an
                  improvement of existing rank-minimization techniques
                  to do regularization. We also demonstrate that we
                  can perform seismic data regularization and
                  interpolation simultaneously. We illustrate the
                  advantages of the modification using a real seismic
                  line from the Gulf of Suez to obtain high quality
                  results for regularization and interpolation, a key
                  application in exploration geophysics.},
  keywords = {EAGE, regularization, interpolation, matrix completion, NFFT},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/kumar2015EAGEmcu/kumar2015EAGEmcu.html}
}


@UNPUBLISHED{kumar2015sss,
  author = {Rajiv Kumar and Haneet Wason and Felix J. Herrmann},
  title = {Source separation for simultaneous towed-streamer marine acquisition---a compressed sensing approach},
  year = {2015},
  abstract = {Simultaneous marine acquisition is an economic way to
                  sample seismic data and speedup acquisition, wherein
                  single and/or multiple source vessels fire sources
                  at near-simultaneous or slightly random times,
                  resulting in overlapping shot records. The current
                  paradigm for simultaneous towed-streamer marine
                  acquisition incorporates "low-variability" in source
                  firing times---i.e., $\leq$ 1 or 2 seconds, since
                  both the sources and receivers are moving. This
                  results in low degree of randomness in simultaneous
                  data, which is challenging to separate (into its
                  constituent sources) using compressed sensing based
                  separation techniques since randomization is the key
                  to successful recovery via compressed sensing. In
                  this paper, we address the challenge of source
                  separation for simultaneous towed-streamer
                  acquisitions via two compressed sensing based
                  approaches---i.e., sparsity-promotion and
                  rank-minimization. We illustrate the performance of
                  both the sparsity-promotion and rank-minimization
                  based techniques by simulating two simultaneous
                  towed-streamer acquisition scenarios---i.e.,
                  over/under and simultaneous long offset. We observe
                  that the proposed approaches give good and
                  comparable recovery qualities of the separated
                  sources, but the rank-minimization technique is
                  relatively faster and memory efficient. We also
                  compare these two techniques with the NMO-based
                  median filtering type approach.},
  keywords = {simultaneous marine acquisition, source separation, sparsity, rank, private},
  note = {Submitted to Geophysics on February 16.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/kumar2015sss/kumar2015sss.html}
}


@UNPUBLISHED{li2015GEOPmgn,
  author = {Xiang Li and Ernie Esser and Felix J. Herrmann},
  title = {Modified {Gauss}-{Newton} full-waveform inversion explained—why sparsity-promoting updates do matter},
  year = {2015},
  abstract = {Full-waveform inversion can be formulated as a nonlinear
                  least-squares optimization problem. This non-convex
                  problem can be extremely computationally expensive
                  because it requires repeatedly solving large linear
                  systems that correspond to discretized partial
                  differential equations. Randomized subsampling
                  techniques allow us to work with small subsets of
                  (monochromatic) source experiments, reducing the
                  computational cost. However, this subsampling
                  weakens subsurface illumination and introduces
                  subsampling related incoherent artifacts. These
                  subsampling-related artifacts---in conjunction with
                  local minima that are known to plague full-waveform
                  inversion---motivate us to come up with a technique
                  to "regularize" this problem. Following earlier
                  work, we take advantage of the fact that curvelets
                  represent subsurface models and perturbations
                  parsimoniously. At first impulse promoting sparsity
                  on the model directly seems the most natural way to
                  proceed, but we will demonstrate that in certain
                  cases it can be advantageous to promote sparsity on
                  the Gauss-Newton updates instead. While constraining
                  the one-norm of the descent directions does not
                  change not change the underlying full-waveform
                  inversion objective, the constrained model updates
                  remain descent directions, remove
                  subsampling-related artifacts and improve the
                  overall inversion result. We empirically observe
                  this phenomenon in situations where the different
                  model updates occur at roughly the same locations in
                  the curvelet domain. We further investigate and
                  analyze this phenomenon, where nonlinear inversions
                  benefit from sparsity-promoting constraints on the
                  updates, by means of a set of carefully selected
                  examples including phase retrieval and full-waveform
                  inversion. In all cases, we observe a faster decay
                  of the residual and model error as a function of the
                  number of iterations.},
  keywords = {full-waveform inversion, Gauss-Newton method, sparsity promotion, private},
  note = {Submitted to Geophysics on May 6.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/li2015GEOPmgn/li2015GEOPmgn.pdf}
}


@UNPUBLISHED{lin2015scatterEPSI,
  author = {Tim T.Y. Lin and Felix J. Herrmann},
  title = {Estimation of primaries by sparse inversion with scattering-based multiple predictions for data with large gaps},
  year = {2015},
  abstract = {We propose to solve the Estimation of Primaries by
                  Sparse Inversion problem without any explicit data
                  reconstruction, from a seismic record with missing
                  near-offsets and large holes in the acquisition grid
                  which does not produce aliasing but otherwise causes
                  large errors in the multiple prediction. Exclusion
                  of the unknown data as an inversion variable from
                  the process is desirable, since it sidesteps
                  possible issues arising from fitting observations
                  that are also unknowns in the same inversion
                  problem. Instead, we simulate their multiple
                  contributions by augmenting the forward prediction
                  model for the total wavefield with a scattering
                  series that mimics the action of the free surface
                  reflector within the confines of the unobserved
                  trace locations. Each term in this scattering series
                  simply involves convolution of the predicted
                  wavefield once more with the current estimated
                  surface-free Green's function at these unobserved
                  locations. We investigate the necessary
                  modifications to the primary estimation algorithm to
                  account for the resulting nonlinearity in the
                  modeling operator, and also demonstrate that just a
                  few scattering terms are enough to satisfactorily
                  mitigate the effects of near-offset data gaps during
                  the inversion process. Numerical experiments on
                  synthetic data show that the final derived method
                  can significantly outperform explicit data
                  reconstruction for large near-offset gaps. This is
                  achieved with a similar computational cost and
                  better memory efficiency compared to explicit data
                  reconstruction. We also show on real data that our
                  scheme outperforms pre-interpolation of the
                  near-offset gap.},
  keywords = {multiples, REPSI, EPSI, scattering, sparsity, optimization, private},
  note = {Submitted to Geophysics on May 5.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/lin2015scatterEPSI/lin2015scatterEPSI.html}
}


@UNPUBLISHED{lopez2015EAGErma,
  author = {Oscar Lopez and Rajiv Kumar and Felix J. Herrmann},
  title = {Rank minimization via alternating optimization: seismic data interpolation},
  year = {2015},
  abstract = {Low-rank matrix completion techniques have recently
                  become an effective tool for seismic trace
                  interpolation problems. In this talk, we consider an
                  alternating optimization scheme for nuclear norm
                  minimization and discuss the applications to large
                  scale wave field reconstruction. By adopting a
                  factorization approach to the rank minimization
                  problem we write our low-rank matrix in bi-linear
                  form, and modify this workflow by alternating our
                  optimization to handle a single matrix factor at a
                  time. This allows for a more tractable procedure
                  that can robustly handle large scale, highly
                  oscillatory and critically subsampled seismic data
                  sets. We demonstrate the potential of this approach
                  with several numerical experiments on a seismic line
                  from the Nelson 2D data set and a frequency slice
                  from the Gulf of Mexico data set.},
  keywords = {EAGE, matrix completion, low-rank, interpolation},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/lopez2015EAGErma/lopez2015EAGErma.html}
}


@UNPUBLISHED{louboutin2015SEGtcs,
  author = {Mathias Louboutin and Felix J. Herrmann},
  title = {Time compressively sampled full-waveform inversion with stochastic optimization},
  year = {2015},
  abstract = {Time-domain Full-Waveform Inversion (FWI) aims to image
                  the subsurface of the earth accurately from field
                  recorded data and can be solved via the reduced
                  adjoint-state method. However, this method requires
                  access to the forward and adjoint wavefields that
                  are meet when computing gradient updates. The
                  challenge here is that the adjoint wavefield is
                  computed in reverse order during time stepping and
                  therefore requires storage or other type of
                  mitigation because storing the full time history of
                  the forward wavefield is too expensive in realistic
                  3D settings. To overcome this challenge, we propose
                  an approximate adjoint-state method where the
                  wavefields are subsampled randomly, which
                  drastically the amount of storage needed. By using
                  techniques from stochastic optimization, we control
                  the errors induced by the subsampling. Examples of
                  the proposed technique on a synthetic but realistic
                  2D model show that the subsampling-related artifacts
                  can be reduced significantly by changing the
                  sampling for each source after each model
                  update. Combination of this gradient approximation
                  with a quasi-Newton method shows virtually artifact
                  free inversion results requiring only 5% of storage
                  compared to saving the history at Nyquist. In
                  addition, we avoid having to recompute the
                  wavefields as is required by checkpointing.},
  keywords = {SEG, Full-waveform inversion, Acoustic, Subsampling, Time-domain, Inversion, Stochastic optimization, private},
  note = {(submitted to the SEG conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Conferences/SEG/2015/louboutin2015SEGtcs/louboutin2015SEGtcs.html}
}


@UNPUBLISHED{oghenekohwo2015EAGEuci,
  author = {Felix Oghenekohwo and Rajiv Kumar and Ernie Esser and Felix J. Herrmann},
  title = {Using common information in compressive time-lapse full-waveform inversion},
  year = {2015},
  abstract = {The use of time-lapse seismic data to monitor changes in
                  the subsurface has become standard practice in
                  industry. In addition, full-waveform inversion has
                  also been extended to time-lapse seismic to obtain
                  useful time-lapse information. The computational
                  cost of this method are becoming more pronounced as
                  the volume of data increases. Therefore, it is
                  necessary to develop fast inversion algorithms that
                  can also give improved time-lapse results. Rather
                  than following existing joint inversion algorithms,
                  we are motivated by a joint recovery model which
                  exploits the common information among the baseline
                  and monitor data. We propose a joint inversion
                  framework, leveraging ideas from distributed
                  compressive sensing and the modified Gauss-Newton
                  method for full-waveform inversion, by using the
                  shared information in the time-lapse data. Our
                  results on a realistic synthetic example highlight
                  the benefits of our joint inversion approach over a
                  parallel inversion method that does not exploit the
                  shared information. Preliminary results also
                  indicate that our formulation can address time-lapse
                  data with inconsistent acquisition geometries.},
  keywords = {EAGE, time-lapse, FWI},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/oghenekohwo2015EAGEuci/oghenekohwo2015EAGEuci.html}
}


@UNPUBLISHED{peters2015AIPwri,
  author = {Bas Peters and Felix J. Herrmann},
  title = {Wavefield-reconstruction inversion},
  year = {2015},
  date_submitted = {04/17/2015},
  abstract = {Wavefield Reconstruction Inversion is a method for
                  PDE-constrained optimization, which revolves around
                  the estimation of fields using the PDE as well as
                  the observed data in a least-squares sense. The
                  method is quadratic penalty based, which offers some
                  interesting possibilities for the construction of
                  algorithms, compared to the Lagrangian form. One of
                  the main benefits of the method is when the initial
                  guess is far from the global minimizer.
                  Reduced-space and full-space algorithms are
                  discussed, including illustrative examples. The
                  method was developed with seismic applications in
                  mind, but applies to other PDE-constrained
                  optimization problems as well.},
  keywords = {AIP, Waveform reconstruction inversion, penalty method, optimization, full-waveform inversion, private},
  note = {to be presented at the AIP Conference in Helsinki, Finland}
}


@UNPUBLISHED{peters2015SEGrwi,
  author = {Bas Peters and Zhilong Fang and Brendan Smithyman and Felix J. Herrmann},
  title = {Regularizing waveform inversion by projections onto convex sets --- application to the {2D} {Chevron} 2014 synthetic blind-test dataset},
  year = {2015},
  abstract = {A framework is proposed for regularizing the waveform
                  inversion problem by projections onto intersections
                  of convex sets. Multiple pieces of prior information
                  about the geology are represented by multiple convex
                  sets, for example limits on the velocity or minimum
                  smoothness conditions on the model.  The data-misfit
                  is then minimized, such that the estimated model is
                  always in the intersection of the convex
                  sets. Therefore, it is clear what properties the
                  estimated model will have at each iteration. This
                  approach does not require any quadratic penalties to
                  be used and thus avoids the known problems and
                  limitations of those types of penalties. It is shown
                  that by formulating waveform inversion as a
                  constrained problem, regularization ideas such as
                  Tikhonov regularization and gradient filtering can
                  be incorporated into one framework. The algorithm is
                  generally applicable, in the sense that it works
                  with any (differentiable) objective function and
                  does not require significant additional
                  computation. The method is demonstrated on the
                  inversion of the 2D marine isotropic elastic
                  synthetic seismic benchmark by Chevron using an
                  acoustic modeling code. To highlight the effect of
                  the projections, we apply no data pre-processing.},
  keywords = {SEG, Waveform inversion, regularization, projection, blind-test,Wavefield Reconstruction Inversion, private},
  note = {(submitted to the SEG conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Conferences/SEG/2015/peters2015SEGrwi/peters2015SEGrwi.html}
}


@UNPUBLISHED{smithyman2015EAGEcwi,
  author = {Brendan Smithyman and Bas Peters and Felix J. Herrmann},
  title = {Constrained waveform inversion of colocated {VSP} and surface seismic data},
  year = {2015},
  abstract = {Constrained Full-Waveform Inversion (FWI) is applied to
                  produce a high-resolution velocity model from both
                  Vertical Seismic Profiling (VSP) and surface seismic
                  data. The case study comes from the Permian Basin in
                  Texas, USA. This dataset motivates and tests several
                  new developments in methodology that enable recovery
                  of model results that sit within multiple a priori
                  constraint sets. These constraints are imposed
                  through a Projected Quasi-Newton (PQN) approach,
                  wherein the projection set is the intersection of
                  physical property bounds and anisotropic wavenumber
                  filtering. This enables the method to recover
                  geologically-reasonable models while preserving the
                  fast model convergence offered by a quasi-Newton
                  optimization scheme like l-BFGS. In the Permian
                  Basin example, low-frequency data from both arrays
                  are inverted together and regularized by this
                  projection approach. Careful choice of the
                  constraint sets is possible without requiring
                  tradeoff parameters as in a quadratic penalty
                  approach to regularization. Multiple 2D FWI results
                  are combined to produce an interpolated 3D model
                  that is consistent with the models from migration
                  velocity analysis and VSP processing, while offering
                  improved resolution and illumination of features
                  from both datasets.},
  keywords = {EAGE, waveform inversion, VSP},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/smithyman2015EAGEcwi/smithyman2015EAGEcwi.pdf}
}
 

@UNPUBLISHED{tu2015GJIsem,
  author = {Ning Tu and Aleksandr Y. Aravkin and Tristan van Leeuwen and Tim T.Y. Lin and Felix J. Herrmann},
  title = {Source estimation with multiples—fast ambiguity-resolved seismic imaging},
  year = {2015},
  abstract = {We propose a fast "wavelet-free" least-squares imaging
                  procedure that produces high-accuracy seismic images
                  without the knowledge of the source
                  wavelet. Conventional reverse-time migration
                  requires the knowledge of the source wavelet, which
                  is either unavailable or very difficult to
                  accurately determine; inaccurate estimates of the
                  source wavelet can result in seriously degraded
                  reverse-time migrated images, and therefore wrong
                  geological interpretations. To solve this problem,
                  we present a "wavelet-free" imaging procedure that
                  simultaneously inverts for the source wavelet and
                  the seismic image, by tightly integrating source
                  estimation into a fast least-squares imaging
                  framework, namely compressive imaging, given a
                  reasonably accurate background velocity
                  model. However, this joint inversion problem is
                  difficult to solve as it is plagued with local
                  minima and the ambiguity with respect to amplitude
                  scalings, because of the multiplicative, and
                  therefore nonlinear, appearance of the source
                  wavelet in the otherwise linear formalism. We have
                  found a way to solve this nonlinear joint-inversion
                  problem using a technique called variable
                  projection, and a way to overcome the scaling
                  ambiguity by including surface-related multiples in
                  our imaging procedure following recent developments
                  in surface-related multiple prediction by sparse
                  inversion. As a result, we obtain highly accurate
                  estimates of the source wavelet and high-resolution
                  seismic images, comparable in quality to images
                  obtained assuming the true source wavelet is
                  known. By leveraging the computationally efficient
                  compressive-imaging methodology, these results are
                  obtained at affordable computational costs compared
                  with conventional processing work flows that include
                  surface-related multiple removal and reverse-time
                  migration.},
  keywords = {inverse theory, time series analysis, computational seismology, wave propagation, free surface, multiples, seismic imaging, private},
  note = {Submitted to Geophysical Journal International on May 14.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/tu2015GJIsem/tu2015GJIsem.html}
}


@UNPUBLISHED{vanleeuwen2015EAGEafs,
  author = {Tristan van Leeuwen and Rajiv Kumar and Felix J. Herrmann},
  title = {Affordable full subsurface image volume---an application to {WEMVA}},
  year = {2015},
  abstract = {Common image gathers are used in building velocity
                  models, inverting for anisotropy parameters, and
                  analyzing reservoir attributes. In this paper, we
                  offer a new perspective on image gathers, where we
                  glean information from the image volume via
                  efficient matrix-vector products. The proposed
                  formulation make the computation of full subsurface
                  image volume feasible. We illustrate how this
                  matrix-vector product can be used to construct
                  objective functions for automatic MVA.},
  keywords = {EAGE, MVA, wave-equation, randomized trace estimation},
  note = {(to be presented at the EAGE conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/vanleeuwen2015EAGEafs/vanleeuwen2015EAGEafs.pdf}
}


@UNPUBLISHED{vanleeuwen2015GPWEMVA,
  author = {Tristan van Leeuwen and Rajiv Kumar and Felix J. Herrmann},
  title = {Affordable omnidirectional subsurface extended image volumes},
  year = {2015},
  abstract = {Image gathers as a function of subsurface offset are an
                  important tool for the inference of rock properties
                  and velocity analysis in areas of complex
                  geology. Traditionally, these gathers are thought of
                  as multidimensional correlations of the source and
                  receiver wavefields. The bottleneck in computing
                  these gathers lies in the fact that one needs to
                  store, compute, and correlate these wavefields in
                  order to obtain the desired image
                  gathers. Therefore, the image gathers are typically
                  only computed for a limited number of subsurface
                  points and for a limited range of subsurface
                  offsets. In this paper, we offer a new perspective
                  on such gathers by organizing the extended image, as
                  a function of all subsurface offsets and all
                  subsurface points, into a matrix whose (i,j)th entry
                  captures the interaction between gridpoints i and
                  j. Of course, it is infeasible to form and store
                  this matrix explicitly. Instead, we propose an
                  efficient algorithm to glean information from the
                  image volume via matrix-vector products, which can
                  be computed efficiently. The probing techniques have
                  two main advantages; i) by using all subsurface
                  offsets, we can handle complex geological structures
                  with steep dips, ii) we can probe the whole model
                  simultaneously and do not have to pick points at
                  which to compute the image gathers. We illustrate
                  these advantages using two important applications of
                  image gathers: amplitude-versus-angle reflectivity
                  analysis and migration velocity analysis.},
  keywords = {migration velocity analysis, AVA, stochastic optimization, private},
  note = {Submitted to Geophysical Prospecting on May 6.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/vanleeuwen2015GPWEMVA/vanleeuwen2015GPWEMVA.pdf}
}


@UNPUBLISHED{vanleeuwen2015IPpmp,
  author = {Tristan van Leeuwen and Felix J. Herrmann},
  title = {A penalty method for {PDE}-constrained optimization in inverse problems},
  year = {2015},
  abstract = {Many inverse and parameter estimation problems can be
                  written as PDE-constrained optimization
                  problems. The goal, then, is to infer the
                  parameters, typically coefficients of the PDE, from
                  partial measurements of the solutions of the PDE for
                  several right-hand-sides. Such PDE-constrained
                  problems can be solved by finding a stationary point
                  of the Lagrangian, which entails simultaneously
                  updating the parameters and the (adjoint) state
                  variables. For large-scale problems, such an
                  all-at-once approach is not feasible as it requires
                  storing all the state variables. In this case one
                  usually resorts to a reduced approach where the
                  constraints are explicitly eliminated (at each
                  iteration) by solving the PDEs. These two
                  approaches, and variations thereof, are the main
                  workhorses for solving PDE-constrained optimization
                  problems arising from inverse problems. In this
                  paper, we present an alternative method that aims to
                  combine the advantages of both approaches. Our
                  method is based on a quadratic penalty formulation
                  of the constrained optimization problem. By
                  eliminating the state variable, we develop an
                  efficient algorithm that has roughly the same
                  computational complexity as the conventional reduced
                  approach while exploiting a larger search
                  space. Numerical results show that this method
                  indeed reduces some of the non-linearity of the
                  problem and is less sensitive the initial iterate.},
  keywords = {penalty method, PDE, optimization, inverse problems, private},
  note = {Submitted to Inverse Problems on April 10.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/vanleeuwen2015IPpmp/vanleeuwen2015IPpmp.pdf}
}


@UNPUBLISHED{wang2015SIAMsdc,
  author = {Rongrong Wang and Felix J. Herrmann and Ozgur Yilmaz},
  title = {A stable data-constrained formulation of full-waveform inversion with wavefield reconstruction for few principle sources},
  year = {2015},
  abstract = {We avoid local minima related to cycle skipping by
                  considering a modified data-constrained FWI
                  formulation where observed data is fitted
                  exactly. This formulation is a well-conditioned
                  limit of the Lagrangian dual of Wavefield
                  Reconstruction Inversion. To mitigate instabilities,
                  we use a source encoding strategy based on singular
                  vectors of the wavefields. In addition, we propose a
                  frugal SVD that efficiently computes the principle
                  components of the wavefields directly from the
                  data.},
  keywords = {SIAM, FWI, private},
  note = {(to be presented at the SIAM Conference on Mathematical and Computational Issues in the Geosciences, June 29 - July 2, Stanford University, California)}
}


@UNPUBLISHED{wason2015EAGEcsm,
  author = {Haneet Wason and Felix Oghenekohwo and Felix J. Herrmann},
  title = {Compressed sensing in {4-D marine}---recovery of dense time-lapse data from subsampled data without repetition},
  year = {2015},
  abstract = {We present an extension of our time-jittered marine
                  acquisition for time-lapse surveys by working on
                  more realistic field acquisition scenarios by
                  incorporating irregular spatial grids without
                  insisting on repeatability between the
                  surveys. Since we are always subsampled in both the
                  baseline and monitor surveys, we are interested in
                  recovering the densely sampled baseline and monitor,
                  and then the (complete) 4-D difference from
                  subsampled/incomplete baseline and monitor data.},
  keywords = {EAGE, simultaneous acquisition, time-lapse, off-the-grid, NFFT},
  note = {(to be presented at the EAGE Conference)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/wason2015EAGEcsm/wason2015EAGEcsm.html}
}



%-----2014-----%

@UNPUBLISHED{dasilva2014htuck,
  author = {Curt Da Silva and Felix J. Herrmann},
  title = {Optimization on the {Hierarchical} {Tucker} manifold - applications to tensor completion},
  year = {2014},
  month = {04},
  abstract = {In this work, we develop an optimization framework for
                  problems whose solutions are well-approximated by
                  Hierarchical Tucker (HT) tensors, an efficient
                  structured tensor format based on recursive subspace
                  factorizations. By exploiting the smooth manifold
                  structure of these tensors, we construct standard
                  optimization algorithms such as Steepest Descent and
                  Conjugate Gradient for completing tensors from
                  missing entries. Our algorithmic framework is fast
                  and scalable to large problem sizes as we do not
                  require SVDs on the ambient tensor space, as
                  required by other methods. Moreover, we exploit the
                  structure of the Gramian matrices associated with
                  the HT format to regularize our problem, reducing
                  overfitting for high subsampling ratios. We also
                  find that the organization of the tensor can have a
                  major impact on completion from realistic seismic
                  acquisition geometries. These samplings are far from
                  idealized randomized samplings that are usually
                  considered in the literature but are realizable in
                  practical scenarios. Using these algorithms, we
                  successfully interpolate large-scale seismic data
                  sets and demonstrate the competitive computational
                  scaling of our algorithms as the problem sizes
                  grow.},
  keywords = {hierarchical tucker, structured tensor, tensor interpolation, differential geometry, riemannian optimization, gauss newton, private},
  note = {Accepted to be published in the journal - Linear Algebra and its Applications, 2015},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2014/dasilva2014htuck/dasilva2014htuck.pdf}
}


@UNPUBLISHED{kumar2014GEOPemc,
  author = {Rajiv Kumar and Curt Da Silva and Okan Akalin and Aleksandr Y. Aravkin and Hassan Mansour and Ben Recht and Felix J. Herrmann},
  title = {Efficient matrix completion for seismic data reconstruction},
  year = {2014},
  month = {08},
  abstract = {Despite recent developments in improved acquisition,
                  seismic data often remains undersampled along source
                  and/or receiver coordinates, resulting in incomplete
                  data for key applications such as migration and
                  multiple prediction requiring densely sampled,
                  alias-free wide azimuth data. When seismic data is
                  organized in monochromatic frequency slices,
                  missing-trace interpolation can be cast into a
                  matrix completion problem, where the low-rank
                  structure of seismic data in the appropriate domain
                  can be exploited to recover densely sampled data
                  volumes from data with missing entries. Current
                  approaches that exploit low-rank structure are based
                  on repeated singular value decompositions, which
                  become prohibitively expensive for large-scale
                  problems unless the data is partitioned and
                  processed in small windows. While computationally
                  manageable, our theory and experiments show degraded
                  results when the windows sizes become too small. To
                  overcome this problem, we carry out our
                  interpolations for each frequency independently
                  while working with the complete data in the
                  midpoint-offset domain instead of windowing. For
                  lateral varying geologies that are not too complex,
                  working in the midpoint-offset domain leads to
                  favorable rank minimization recovery because the
                  singular values decay faster while sampling-related
                  artifacts remain full rank. This combination of fast
                  decay and full-rank artifacts agrees with the
                  principles of the compressive sensing paradigm,
                  which is based on exploiting (low-rank) structure, a
                  sampling process that breaks this structure, and a
                  rank-minimizing optimization that restores the
                  signal's structure and interpolates the subsampled
                  data. To make our proposed method computationally
                  viable and practical, we introduce a
                  factorization-based approach that avoids computing
                  the singular values, and that therefore scales to
                  large seismic data problems as long as the factors
                  can be stored in memory. Tests on realistic two- and
                  three-dimensional seismic data show that our method
                  compares favorably, both in terms of computational
                  speed and recovery quality, to existing
                  curvelet-based and tensor-based techniques.},
  keywords = {interpolation, low-rank, private},
  note = {Submitted to Geophysics on August 8, 2014.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2014/kumar2014GEOPemc/kumar2014GEOPemc.pdf}
}


@UNPUBLISHED{oghenekohwo2014GEOPfrt,
  author = {Felix Oghenekohwo and Haneet Wason and Ernie Esser and Felix J. Herrmann},
  title = {Compressive 4D—economic time-lapse seismic with randomized subsampling and joint recovery},
  year = {2014},
  month = {10},
  abstract = {The current paradigm of time-lapse seismic relies on
                  dense sampling and repeatability amongst the
                  baseline and the monitor surveys. Recent results in
                  distributed compressive sensing allow us to come up
                  with a new economic sampling paradigm where the
                  vintages and time-lapse difference are recovered
                  from incomplete data. The combination of randomized
                  sampling, signal structure and correlations among
                  the vintages underlies this approach. In a somewhat
                  idealized setting where effects such as difference
                  in currents are ignored, and where we do not have
                  access to dense samplings of the baseline and/or
                  monitor surveys, we can get high quality recovery of
                  these vintages and time-lapse difference when there
                  is a small “overlap” in the surveys—i.e., where the
                  random samplings have partial statistical
                  dependence. Specifically, we find that the quality
                  of the vintages improves for decreasing overlap in
                  the surveys while the converse is true for the
                  time-lapse difference. Our setting differs from
                  conventional time-lapse acquisition because we do
                  not have access to dense samplings. Surveys with
                  partial overlapping randomized samplings lead to the
                  best trade-off between the recovery quality of the
                  vintages and the time-lapse signal. We confirm this
                  by a series of experiments.},
  keywords = {acquistion, time-lapse, marine, sampling, random, joint recovery method, private},
  note = {Submitted revision 1 to Geophysics on October 22, 2014},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2014/oghenekohwo2014GEOPfrt/oghenekohwo2014GEOPfrt.html}
}


%-----2013-----%

@UNPUBLISHED{ghadermarzy2013ncs,
  author = {Navid Ghadermarzy and Hassan Mansour and Ozgur Yilmaz},
  title = {Non-convex compressed sensing using partial support information},
  year = {2013},
  abstract = {In this paper we address the recovery conditions of
                  weighted $\ell_p$ minimization for signal reconstruction
                  from compressed sensing measurements when partial
                  support in- formation is available. We show that
                  weighted $\ell_p$ minimization with 0 < p < 1 is stable
                  and robust under weaker sufficient conditions
                  compared to weighted $\ell_1$ minimization. Moreover, the
                  sufficient recovery conditions of weighted $\ell_p$ are
                  weaker than those of regular $\ell_p$ minimization if at
                  least 50\% of the support estimate is accurate. We
                  also review some algorithms which exist to solve the
                  non-convex $\ell_p$ problem and illustrate our results
                  with numerical experiments.},
  keywords = {Compressed sensing, weighted $\ell_p$, nonconvex optimization, sparse reconstruction},
  month = {11},
  url = {http://arxiv.org/abs/1311.3773}
}

